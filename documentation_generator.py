from __future__ import annotations

import argparse
import hashlib
import json
import logging
import os
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Optional

logger = logging.getLogger(__name__)


DOCS_DIR = Path(__file__).parent / "docs"
ARCH_PATH = DOCS_DIR / "ARCHITECTURE.md"
STATE_PATH = DOCS_DIR / ".autogen_state.json"
DEFAULT_COLLECTION_NAME = "indian_legal_rag"
DEFAULT_LOCAL_STATE_DIR = Path(__file__).parent / "chrome_langchain_db"
DEFAULT_EMBED_DIM_PATH = DEFAULT_LOCAL_STATE_DIR / "embed_dim.json"


@dataclass(frozen=True)
class SystemConfig:
    embedding_model: str
    milvus_host: str
    milvus_port: int
    milvus_collection: str
    milvus_metric: str
    milvus_index_type: str
    embedding_dim: int

    neo4j_uri: str
    neo4j_user: str

    enable_graph: bool

    @staticmethod
    def load() -> "SystemConfig":
        embedding_model = os.environ.get("EMBEDDING_MODEL", "nomic-embed-text")
        milvus_host = os.environ.get("MILVUS_HOST", "localhost")
        milvus_port = int(os.environ.get("MILVUS_PORT", "19530"))
        milvus_collection = os.environ.get("MILVUS_COLLECTION", DEFAULT_COLLECTION_NAME)
        milvus_metric = os.environ.get("MILVUS_METRIC", "COSINE")
        milvus_index_type = os.environ.get("MILVUS_INDEX_TYPE", "HNSW")
        embedding_dim = 0
        env_dim = os.environ.get("EMBEDDING_DIM")
        if env_dim:
            try:
                embedding_dim = int(env_dim)
            except Exception:
                embedding_dim = 0
        if not embedding_dim and DEFAULT_EMBED_DIM_PATH.exists():
            try:
                payload = json.loads(DEFAULT_EMBED_DIM_PATH.read_text(encoding="utf-8"))
                embedding_dim = int(payload.get("dim") or 0)
            except Exception:
                embedding_dim = 0

        neo4j_uri = os.environ.get("NEO4J_URI", "bolt://localhost:7687")
        neo4j_user = os.environ.get("NEO4J_USER", "neo4j")
        enable_graph = os.environ.get("ENABLE_GRAPH", "0").strip().lower() in {"1", "true", "yes", "on"}

        return SystemConfig(
            embedding_model=embedding_model,
            milvus_host=milvus_host,
            milvus_port=milvus_port,
            milvus_collection=milvus_collection,
            milvus_metric=milvus_metric,
            milvus_index_type=milvus_index_type,
            embedding_dim=embedding_dim,
            neo4j_uri=neo4j_uri,
            neo4j_user=neo4j_user,
            enable_graph=enable_graph,
        )


def _repo_signature(cfg: SystemConfig) -> str:
    """
    Lightweight signature used to avoid regenerating docs on every ingestion.
    Includes config + a hash of key source files.
    """
    h = hashlib.sha256()
    h.update(json.dumps(cfg.__dict__, sort_keys=True).encode("utf-8"))

    for path in sorted(Path(__file__).parent.glob("*.py")):
        try:
            h.update(path.name.encode("utf-8"))
            h.update(path.read_bytes())
        except Exception:
            continue
    return h.hexdigest()


def _render_architecture_md(cfg: SystemConfig) -> str:
    dim = cfg.embedding_dim or "(auto-detected at runtime)"
    return f"""# LegalAid AI — Hybrid Legal RAG Architecture (Milvus + Neo4j)

Generated by `documentation_generator.py`. This document is intended to stay in sync with the codebase.

## Architecture Overview

```mermaid
flowchart LR
  subgraph UI[Streamlit Frontend]
    st[Streamlit App]
  end

  subgraph ORCH[Orchestration Layer (Python)]
    router[Query Router]
    ent[Entity Extraction]
    graphq[Graph Traversal]
    vecq[Vector Retrieval]
    rr[Reranking]
    conf[Confidence Scoring]
    ctx[Context Builder]
    llm[LLM Synthesis (Ollama)]
  end

  subgraph VEC[Vector Layer]
    milvus[(Milvus)]
  end

  subgraph GDB[Graph Layer]
    neo4j[(Neo4j)]
  end

  st --> router --> ent
  ent --> graphq --> neo4j
  ent --> vecq --> milvus
  graphq --> vecq
  vecq --> rr --> conf --> ctx --> llm --> st
```

## Technology Choices & Trade-offs

- **Milvus over Chroma**: better scaling characteristics (collections, indexing options, durability via external storage), robust filtering/search at larger sizes. Trade-offs: operational complexity (services + monitoring), schema/index management.
- **Neo4j graph layer**: enables Act/Section neighborhood traversal (e.g., *Section 27* → cited/related sections) and deterministic structure-aware filtering; helps recall/precision for statute-heavy queries. Trade-offs: extra ingestion complexity and eventual consistency between vector+graph stores.
- **Hybrid retrieval**: vector similarity (semantic) + BM25 (lexical) improves legal retrieval where exact statutory phrasing matters.

## Deployment Architecture

Local Docker Compose: `infra/docker-compose.yml` brings up:
- Milvus (etcd + minio + standalone) on `localhost:{cfg.milvus_port}`
- Neo4j on `localhost:7687` / `localhost:7474`

## Vector Schema (Milvus)

Collection: `{cfg.milvus_collection}`
- Primary key: `doc_id` (stable IDs preserved)
- Vector: `embedding` (FloatVector, dim={dim}, metric={cfg.milvus_metric})
- Payload: `text` + core metadata fields (`act`, `section`, `doc_type`, `source`, etc.)
- Full metadata preserved in `metadata_json` for forward compatibility

Index recommendation:
- Default: **HNSW** for low-latency + good recall on medium-sized corpora
- Consider IVF_FLAT/IVF_PQ for multi-million scale or constrained memory

## Graph Schema (Neo4j)

Nodes (requested):
- `(:Act {{name}})`
- `(:Section {{key, act, section, subsection, clause, citation}})`
- `(:Case {{name}})` (reserved for future extraction improvements)
- `(:Amendment {{id}})` (reserved)

Additional node (practical necessity for chunk-level retrieval):
- `(:Chunk {{doc_id, source, source_path, doc_type}})`

Relationships:
- `(Act)-[:HAS_SECTION]->(Section)`
- `(Section)-[:HAS_CHUNK]->(Chunk)`
- `(Section)-[:CITES]->(Section)` (heuristic extraction from chunk text)

## Data Flow

```mermaid
flowchart TB
  A[PDF/MD/JSON sources] --> B[Chunking + Metadata]
  B --> C[Embedding (OllamaEmbeddings)]
  C --> D[Milvus upsert]
  B --> E[Neo4j upsert]
  D --> F[Hybrid Retrieval]
  E --> F
  F --> G[Rerank + Confidence]
  G --> H[LLM Answer]
```

## Sequence Diagrams

### Ingestion
```mermaid
sequenceDiagram
  participant User
  participant Ingest as ingestion_pipeline.py
  participant Vec as Milvus
  participant Graph as Neo4j
  participant Docs as documentation_generator.py

  User->>Ingest: run ingestion
  Ingest->>Vec: upsert chunks + embeddings
  Ingest->>Graph: upsert Act/Section/Chunk + CITES edges
  Ingest->>Docs: regenerate docs if changed
```

### User Query
```mermaid
sequenceDiagram
  participant UI as Streamlit
  participant Orch as orchestrator.py
  participant Graph as Neo4j
  participant Vec as Milvus
  participant LLM as Ollama

  UI->>Orch: query
  Orch->>Orch: extract act/section entities
  Orch->>Graph: traverse neighborhood
  Orch->>Vec: vector search (filtered by graph candidates)
  Orch->>UI: candidate docs (reranked in rag_core.py)
  UI->>LLM: synthesize answer with context
  LLM->>UI: answer + citations
```

## Scaling & Performance Considerations

- **Milvus index selection**
  - HNSW: best general-purpose for interactive latency.
  - IVF_*: better memory scaling; requires tuning `nlist/nprobe`.
- **Batching**
  - Keep embedding batch sizes conservative (Ollama can OOM on huge batches).
  - Use `BATCH_SIZE=32` as a safe default; increase carefully with monitoring.
- **Metadata filtering**
  - Prefer short equality filters (`act`, `source`, `doc_type`).
  - Avoid very large `doc_id in [...]` filters; cap and backfill with global retrieval.
- **Neo4j**
  - Add constraints (done) and keep traversals bounded (`cite_hops`, `limit`).

## Failure Handling

- Vector store failures: retried vector search (`VECTOR_QUERY_RETRIES`) and BM25 fallback.
- Ingestion failures: batch-level try/except; continues on partial failures; maintains manifest.
- Graph layer: optional behind `ENABLE_GRAPH=1`; failures degrade gracefully to vector-only retrieval.

## When Milvus Migration Is Worth It

- Worth it when:
  - Corpus is large (hundreds of thousands+ chunks) and query latency/recall need stronger indexing
  - You need richer server-side filtering, durability, and operational controls
- Chroma may still be sufficient when:
  - Corpus is small and you want minimal infrastructure and fast iteration

## Risks

- Operational complexity (Milvus + Neo4j services, backups, monitoring)
- Schema drift (metadata fields) — mitigated via `metadata_json`
- Embedding dimension mismatch — mitigated via runtime probe + `EMBEDDING_DIM` override

## Roadmap

- Case-law entity extraction (Case nodes + CITES/INTERPRETS/OVERRULES edges)
- Section-level canonicalization across Acts + cross-act citations
- Partitioning by `act` / `doc_type` in Milvus for performance isolation
- Async ingestion + background index builds
"""


def regenerate_docs_if_needed(*, force: bool = False) -> bool:
    DOCS_DIR.mkdir(parents=True, exist_ok=True)
    cfg = SystemConfig.load()
    sig = _repo_signature(cfg)

    old_sig = None
    if STATE_PATH.exists():
        try:
            old_sig = json.loads(STATE_PATH.read_text(encoding="utf-8")).get("signature")
        except Exception:
            old_sig = None

    if not force and old_sig == sig and ARCH_PATH.exists():
        return False

    md = _render_architecture_md(cfg)
    ARCH_PATH.write_text(md, encoding="utf-8", newline="\n")
    STATE_PATH.write_text(json.dumps({"signature": sig}, indent=2), encoding="utf-8", newline="\n")
    logger.info("Regenerated %s", ARCH_PATH)
    return True


def check_docs_up_to_date() -> bool:
    cfg = SystemConfig.load()
    sig = _repo_signature(cfg)
    if not ARCH_PATH.exists() or not STATE_PATH.exists():
        return False
    try:
        old_sig = json.loads(STATE_PATH.read_text(encoding="utf-8")).get("signature")
    except Exception:
        return False
    return old_sig == sig


def main(argv: Optional[list[str]] = None) -> int:
    ap = argparse.ArgumentParser(description="Generate docs/ARCHITECTURE.md (Mermaid-based).")
    ap.add_argument("--check", action="store_true", help="Exit non-zero if docs are out of date")
    ap.add_argument("--force", action="store_true", help="Regenerate even if signature matches")
    ap.add_argument("--log-level", default="INFO")
    args = ap.parse_args(argv)

    logging.basicConfig(level=getattr(logging, args.log_level.upper(), logging.INFO), format="%(levelname)s: %(message)s")

    if args.check:
        ok = check_docs_up_to_date()
        if not ok:
            logger.error("docs/ARCHITECTURE.md is out of date. Run: python documentation_generator.py --force")
        return 0 if ok else 2

    regenerate_docs_if_needed(force=args.force)
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
